{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boernd/tf-in-practice/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "outputId": "860c4c45-8455-4c79-eb0a-18704dc04700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "ae48e168-74cb-4a75-85eb-801d8635afaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(include_top=False, weights=None, input_shape=(150,150,3))\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 20:55:02--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 2404:6800:4008:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  39.0MB/s    in 2.1s    \n",
            "\n",
            "2020-03-06 20:55:04 (39.0 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "d4ee2798-184f-4363-e600-5e09bb6fdf5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "f5cab735-bf45-4575-f501-04ca3cd696d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(units=1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (units=1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.00005), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "f44b55d3-c3d5-4fe6-ec46-7458a026ac85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 20:55:55--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  62.1MB/s    in 2.3s    \n",
            "\n",
            "2020-03-06 20:55:57 (62.1 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-03-06 20:55:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  26.3MB/s    in 0.4s    \n",
            "\n",
            "2020-03-06 20:55:59 (26.3 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "75093454-5f0f-492e-b5a0-432e42d62abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "os.listdir('/tmp/training')\n",
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "89d86700-8dbf-42a5-d1a5-1af56b990c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \n",
        "                                   rotation_range=90, \n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range=0.2, \n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   vertical_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150,150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         target_size=(150,150),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "5950b920-ce16-48a6-97d7-a15e1948d2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=train_generator.samples/32,\n",
        "                              epochs=100,callbacks=[callbacks],\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=validation_generator.samples/32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.4203 - acc: 0.8111Epoch 1/100\n",
            "33/32 [==============================] - 15s 454ms/step - loss: 0.4107 - acc: 0.8169 - val_loss: 0.0265 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9427Epoch 1/100\n",
            "33/32 [==============================] - 11s 346ms/step - loss: 0.2023 - acc: 0.9406 - val_loss: 0.0183 - val_acc: 0.9961\n",
            "Epoch 3/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9497Epoch 1/100\n",
            "33/32 [==============================] - 12s 368ms/step - loss: 0.1534 - acc: 0.9503 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9598Epoch 1/100\n",
            "33/32 [==============================] - 12s 367ms/step - loss: 0.1022 - acc: 0.9581 - val_loss: 0.0053 - val_acc: 0.9961\n",
            "Epoch 5/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9678Epoch 1/100\n",
            "33/32 [==============================] - 12s 365ms/step - loss: 0.1093 - acc: 0.9659 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9719Epoch 1/100\n",
            "33/32 [==============================] - 12s 367ms/step - loss: 0.0809 - acc: 0.9727 - val_loss: 0.0097 - val_acc: 0.9961\n",
            "Epoch 7/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9749Epoch 1/100\n",
            "33/32 [==============================] - 12s 362ms/step - loss: 0.0777 - acc: 0.9727 - val_loss: 0.0571 - val_acc: 0.9805\n",
            "Epoch 8/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9779Epoch 1/100\n",
            "33/32 [==============================] - 12s 351ms/step - loss: 0.0607 - acc: 0.9786 - val_loss: 7.1415e-04 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9749Epoch 1/100\n",
            "33/32 [==============================] - 12s 361ms/step - loss: 0.0761 - acc: 0.9747 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9819Epoch 1/100\n",
            "33/32 [==============================] - 12s 349ms/step - loss: 0.0505 - acc: 0.9825 - val_loss: 0.0106 - val_acc: 0.9961\n",
            "Epoch 11/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9769Epoch 1/100\n",
            "33/32 [==============================] - 12s 361ms/step - loss: 0.0549 - acc: 0.9766 - val_loss: 0.0157 - val_acc: 0.9922\n",
            "Epoch 12/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9849Epoch 1/100\n",
            "33/32 [==============================] - 12s 350ms/step - loss: 0.0546 - acc: 0.9844 - val_loss: 0.0030 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9759Epoch 1/100\n",
            "33/32 [==============================] - 12s 355ms/step - loss: 0.0616 - acc: 0.9757 - val_loss: 2.7986e-04 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9849Epoch 1/100\n",
            "33/32 [==============================] - 12s 358ms/step - loss: 0.0541 - acc: 0.9844 - val_loss: 0.0976 - val_acc: 0.9727\n",
            "Epoch 15/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9899Epoch 1/100\n",
            "33/32 [==============================] - 12s 353ms/step - loss: 0.0330 - acc: 0.9903 - val_loss: 0.0424 - val_acc: 0.9883\n",
            "Epoch 16/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9789Epoch 1/100\n",
            "33/32 [==============================] - 12s 353ms/step - loss: 0.0653 - acc: 0.9786 - val_loss: 4.0029e-05 - val_acc: 1.0000\n",
            "Epoch 17/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9759Epoch 1/100\n",
            "33/32 [==============================] - 12s 354ms/step - loss: 0.0571 - acc: 0.9766 - val_loss: 0.0403 - val_acc: 0.9805\n",
            "Epoch 18/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9829Epoch 1/100\n",
            "33/32 [==============================] - 11s 347ms/step - loss: 0.0456 - acc: 0.9834 - val_loss: 0.0612 - val_acc: 0.9766\n",
            "Epoch 19/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9839Epoch 1/100\n",
            "33/32 [==============================] - 12s 355ms/step - loss: 0.0484 - acc: 0.9844 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 20/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9899Epoch 1/100\n",
            "33/32 [==============================] - 11s 348ms/step - loss: 0.0239 - acc: 0.9903 - val_loss: 0.0172 - val_acc: 0.9922\n",
            "Epoch 21/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9769Epoch 1/100\n",
            "33/32 [==============================] - 12s 356ms/step - loss: 0.0823 - acc: 0.9747 - val_loss: 0.1295 - val_acc: 0.9688\n",
            "Epoch 22/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9819Epoch 1/100\n",
            "33/32 [==============================] - 11s 346ms/step - loss: 0.0377 - acc: 0.9825 - val_loss: 0.0031 - val_acc: 0.9961\n",
            "Epoch 23/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9854Epoch 1/100\n",
            "33/32 [==============================] - 12s 351ms/step - loss: 0.0396 - acc: 0.9854 - val_loss: 0.0286 - val_acc: 0.9961\n",
            "Epoch 24/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9819Epoch 1/100\n",
            "33/32 [==============================] - 12s 351ms/step - loss: 0.0393 - acc: 0.9825 - val_loss: 0.0994 - val_acc: 0.9727\n",
            "Epoch 25/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9849Epoch 1/100\n",
            "33/32 [==============================] - 12s 351ms/step - loss: 0.0440 - acc: 0.9854 - val_loss: 0.0382 - val_acc: 0.9844\n",
            "Epoch 26/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9889Epoch 1/100\n",
            "33/32 [==============================] - 11s 345ms/step - loss: 0.0331 - acc: 0.9893 - val_loss: 0.0142 - val_acc: 0.9961\n",
            "Epoch 27/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9889Epoch 1/100\n",
            "33/32 [==============================] - 11s 345ms/step - loss: 0.0303 - acc: 0.9893 - val_loss: 0.0193 - val_acc: 0.9922\n",
            "Epoch 28/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9879Epoch 1/100\n",
            "33/32 [==============================] - 12s 349ms/step - loss: 0.0774 - acc: 0.9883 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9920Epoch 1/100\n",
            "33/32 [==============================] - 12s 349ms/step - loss: 0.0219 - acc: 0.9922 - val_loss: 6.1817e-05 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9879Epoch 1/100\n",
            "33/32 [==============================] - 12s 353ms/step - loss: 0.0292 - acc: 0.9883 - val_loss: 0.0134 - val_acc: 0.9922\n",
            "Epoch 31/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9859Epoch 1/100\n",
            "33/32 [==============================] - 11s 347ms/step - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0091 - val_acc: 0.9922\n",
            "Epoch 32/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9960Epoch 1/100\n",
            "33/32 [==============================] - 11s 345ms/step - loss: 0.0214 - acc: 0.9961 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9869Epoch 1/100\n",
            "33/32 [==============================] - 12s 355ms/step - loss: 0.0316 - acc: 0.9873 - val_loss: 0.0109 - val_acc: 0.9961\n",
            "Epoch 34/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 351ms/step - loss: 0.0193 - acc: 0.9932 - val_loss: 0.0197 - val_acc: 0.9922\n",
            "Epoch 35/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9932Epoch 1/100\n",
            "33/32 [==============================] - 12s 356ms/step - loss: 0.0239 - acc: 0.9932 - val_loss: 0.0066 - val_acc: 0.9961\n",
            "Epoch 36/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9879Epoch 1/100\n",
            "33/32 [==============================] - 12s 350ms/step - loss: 0.0338 - acc: 0.9883 - val_loss: 0.0093 - val_acc: 0.9922\n",
            "Epoch 37/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9899Epoch 1/100\n",
            "33/32 [==============================] - 12s 359ms/step - loss: 0.0310 - acc: 0.9893 - val_loss: 5.1818e-04 - val_acc: 1.0000\n",
            "Epoch 38/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9879Epoch 1/100\n",
            "33/32 [==============================] - 12s 353ms/step - loss: 0.0490 - acc: 0.9883 - val_loss: 0.0505 - val_acc: 0.9883\n",
            "Epoch 39/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9899Epoch 1/100\n",
            "33/32 [==============================] - 12s 354ms/step - loss: 0.0284 - acc: 0.9903 - val_loss: 0.0657 - val_acc: 0.9844\n",
            "Epoch 40/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9869Epoch 1/100\n",
            "33/32 [==============================] - 12s 356ms/step - loss: 0.0360 - acc: 0.9873 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 41/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9950Epoch 1/100\n",
            "33/32 [==============================] - 12s 357ms/step - loss: 0.0145 - acc: 0.9942 - val_loss: 0.0208 - val_acc: 0.9961\n",
            "Epoch 42/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9910Epoch 1/100\n",
            "33/32 [==============================] - 12s 354ms/step - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0697 - val_acc: 0.9805\n",
            "Epoch 43/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9920Epoch 1/100\n",
            "33/32 [==============================] - 11s 345ms/step - loss: 0.0355 - acc: 0.9922 - val_loss: 0.0290 - val_acc: 0.9922\n",
            "Epoch 44/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9889Epoch 1/100\n",
            "33/32 [==============================] - 12s 356ms/step - loss: 0.0526 - acc: 0.9893 - val_loss: 0.0425 - val_acc: 0.9883\n",
            "Epoch 45/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9869Epoch 1/100\n",
            "33/32 [==============================] - 12s 358ms/step - loss: 0.0364 - acc: 0.9873 - val_loss: 0.0129 - val_acc: 0.9961\n",
            "Epoch 46/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9930Epoch 1/100\n",
            "33/32 [==============================] - 12s 367ms/step - loss: 0.0142 - acc: 0.9932 - val_loss: 0.0156 - val_acc: 0.9961\n",
            "Epoch 47/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9879Epoch 1/100\n",
            "33/32 [==============================] - 12s 357ms/step - loss: 0.0929 - acc: 0.9883 - val_loss: 0.0112 - val_acc: 0.9922\n",
            "Epoch 48/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9960Epoch 1/100\n",
            "33/32 [==============================] - 12s 359ms/step - loss: 0.0127 - acc: 0.9951 - val_loss: 0.0211 - val_acc: 0.9922\n",
            "Epoch 49/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9910Epoch 1/100\n",
            "33/32 [==============================] - 12s 360ms/step - loss: 0.0200 - acc: 0.9912 - val_loss: 0.0558 - val_acc: 0.9883\n",
            "Epoch 50/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9879Epoch 1/100\n",
            "33/32 [==============================] - 12s 355ms/step - loss: 0.0447 - acc: 0.9883 - val_loss: 0.0858 - val_acc: 0.9844\n",
            "Epoch 51/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 353ms/step - loss: 0.0254 - acc: 0.9942 - val_loss: 0.0190 - val_acc: 0.9922\n",
            "Epoch 52/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9980Epoch 1/100\n",
            "33/32 [==============================] - 12s 357ms/step - loss: 0.0328 - acc: 0.9981 - val_loss: 0.0140 - val_acc: 0.9922\n",
            "Epoch 53/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9869Epoch 1/100\n",
            "33/32 [==============================] - 12s 354ms/step - loss: 0.0394 - acc: 0.9873 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 54/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9910Epoch 1/100\n",
            "33/32 [==============================] - 12s 358ms/step - loss: 0.0167 - acc: 0.9912 - val_loss: 0.0637 - val_acc: 0.9844\n",
            "Epoch 55/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9849Epoch 1/100\n",
            "33/32 [==============================] - 12s 357ms/step - loss: 0.0325 - acc: 0.9854 - val_loss: 0.0209 - val_acc: 0.9922\n",
            "Epoch 56/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9910Epoch 1/100\n",
            "33/32 [==============================] - 12s 353ms/step - loss: 0.0251 - acc: 0.9912 - val_loss: 0.0145 - val_acc: 0.9922\n",
            "Epoch 57/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9960Epoch 1/100\n",
            "33/32 [==============================] - 12s 355ms/step - loss: 0.0163 - acc: 0.9961 - val_loss: 0.0427 - val_acc: 0.9922\n",
            "Epoch 58/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9849Epoch 1/100\n",
            "33/32 [==============================] - 12s 358ms/step - loss: 0.0335 - acc: 0.9854 - val_loss: 0.0626 - val_acc: 0.9883\n",
            "Epoch 59/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9980Epoch 1/100\n",
            "33/32 [==============================] - 12s 367ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0317 - val_acc: 0.9922\n",
            "Epoch 60/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9970Epoch 1/100\n",
            "33/32 [==============================] - 12s 365ms/step - loss: 0.0154 - acc: 0.9971 - val_loss: 0.0741 - val_acc: 0.9883\n",
            "Epoch 61/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 364ms/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.0277 - val_acc: 0.9922\n",
            "Epoch 62/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9889Epoch 1/100\n",
            "33/32 [==============================] - 12s 365ms/step - loss: 0.0302 - acc: 0.9893 - val_loss: 0.0680 - val_acc: 0.9844\n",
            "Epoch 63/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9950Epoch 1/100\n",
            "33/32 [==============================] - 12s 361ms/step - loss: 0.0198 - acc: 0.9951 - val_loss: 0.0364 - val_acc: 0.9922\n",
            "Epoch 64/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 369ms/step - loss: 0.0188 - acc: 0.9932 - val_loss: 0.0069 - val_acc: 0.9922\n",
            "Epoch 65/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9920Epoch 1/100\n",
            "33/32 [==============================] - 12s 373ms/step - loss: 0.0620 - acc: 0.9922 - val_loss: 0.0244 - val_acc: 0.9922\n",
            "Epoch 66/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9960Epoch 1/100\n",
            "33/32 [==============================] - 12s 368ms/step - loss: 0.0092 - acc: 0.9961 - val_loss: 0.0278 - val_acc: 0.9922\n",
            "Epoch 67/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9930Epoch 1/100\n",
            "33/32 [==============================] - 12s 363ms/step - loss: 0.0935 - acc: 0.9932 - val_loss: 0.0307 - val_acc: 0.9883\n",
            "Epoch 68/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9899Epoch 1/100\n",
            "33/32 [==============================] - 12s 361ms/step - loss: 0.0306 - acc: 0.9893 - val_loss: 0.0380 - val_acc: 0.9883\n",
            "Epoch 69/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 359ms/step - loss: 0.0132 - acc: 0.9942 - val_loss: 0.0297 - val_acc: 0.9922\n",
            "Epoch 70/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9910Epoch 1/100\n",
            "33/32 [==============================] - 12s 366ms/step - loss: 0.0642 - acc: 0.9912 - val_loss: 0.0608 - val_acc: 0.9883\n",
            "Epoch 71/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9920Epoch 1/100\n",
            "33/32 [==============================] - 12s 359ms/step - loss: 0.0129 - acc: 0.9922 - val_loss: 0.0314 - val_acc: 0.9922\n",
            "Epoch 72/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9930Epoch 1/100\n",
            "33/32 [==============================] - 12s 356ms/step - loss: 0.0144 - acc: 0.9932 - val_loss: 0.0604 - val_acc: 0.9883\n",
            "Epoch 73/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9889Epoch 1/100\n",
            "33/32 [==============================] - 12s 366ms/step - loss: 0.0263 - acc: 0.9893 - val_loss: 0.0416 - val_acc: 0.9883\n",
            "Epoch 74/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 364ms/step - loss: 0.0158 - acc: 0.9942 - val_loss: 0.1523 - val_acc: 0.9766\n",
            "Epoch 75/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 365ms/step - loss: 0.0100 - acc: 0.9942 - val_loss: 0.0856 - val_acc: 0.9805\n",
            "Epoch 76/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9970Epoch 1/100\n",
            "33/32 [==============================] - 12s 358ms/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.0892 - val_acc: 0.9805\n",
            "Epoch 77/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9910Epoch 1/100\n",
            "33/32 [==============================] - 12s 363ms/step - loss: 0.0255 - acc: 0.9912 - val_loss: 0.0114 - val_acc: 0.9922\n",
            "Epoch 78/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 367ms/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.1184 - val_acc: 0.9805\n",
            "Epoch 79/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9950Epoch 1/100\n",
            "33/32 [==============================] - 12s 360ms/step - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0428 - val_acc: 0.9883\n",
            "Epoch 80/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9960Epoch 1/100\n",
            "33/32 [==============================] - 12s 359ms/step - loss: 0.0204 - acc: 0.9961 - val_loss: 0.0487 - val_acc: 0.9844\n",
            "Epoch 81/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9889Epoch 1/100\n",
            "33/32 [==============================] - 12s 359ms/step - loss: 0.0589 - acc: 0.9893 - val_loss: 0.1612 - val_acc: 0.9805\n",
            "Epoch 82/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9940Epoch 1/100\n",
            "33/32 [==============================] - 12s 359ms/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.1240 - val_acc: 0.9805\n",
            "Epoch 83/100\n",
            "32/32 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9960Epoch 1/100\n",
            " 8/32 [======>.......................] - ETA: 4s - loss: 0.1982 - acc: 0.9688"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "f3bbebea-fc6b-4b9c-94ef-0b9b85ef8404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI7Kgp5RSI7Kgp5RSI34CY4HZ5YwwezUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}